{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Payment Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a 2016 study, it was estimated that credit card fraud was responsible for over 20 billion dollars in loss, worldwide. Accurately detecting cases of fraud is an ongoing area of research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeled Data¶\n",
    "The payment fraud data set (Dal Pozzolo et al. 2015) was downloaded from Kaggle. This has features and labels for thousands of credit card transactions, each of which is labeled as fraudulent or valid. In this notebook, we'd like to train a model based on the features of these transactions so that we can predict risky or fraudulent transactions in the future.\n",
    "\n",
    "* It is worth noticing that the column features V1-V28 are the relevant components after being processed and refined by PCA. Kaggle stated that they cannot disclose the features due to confidentiality issue. For such reason, we will work directly with the features without doing any further feature engineering. \n",
    "\n",
    "## Binary Classification\n",
    "Since we have true labels to aim for, we'll take a supervised learning approach and train a binary classifier to sort data into one of our two transaction classes: fraudulent or valid. We'll train a model on training data and see how well it generalizes on some test data.\n",
    "\n",
    "#### The notebook will be broken down into a few steps:\n",
    "\n",
    "1) Loading and exploring the data\n",
    "\n",
    "2) Splitting the data into train/test sets\n",
    "\n",
    "3) Defining and training a LinearLearner, binary classifier\n",
    "\n",
    "4) Making improvements on the model\n",
    "\n",
    "5) Evaluating and comparing model test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, download all of the necessary libraries\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth pointing out that the time feature has bimodal distribution, which we can prove by plotting it in a histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a histogram of Time feature\n",
    "\n",
    "count, bin_edges = np.histogram(df['Time']) # create bin ranges and frequency count\n",
    "df['Time'].plot(kind='hist',color='darkblue',figsize = (7,4), xticks = bin_edges)\n",
    "\n",
    "plt.title('Histogram of Time Elapses between transactions')\n",
    "plt.xlabel('Number of seconds')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xbb310f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "count,bin_edges = np.histogram(df['Time'])\n",
    "sns.distplot(df['Time'], hist=True, kde=True, \n",
    "             bins=bin_edges, color = 'darkblue',\n",
    "             kde_kws={'linewidth': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraudulent percentage =  0.1727485630620034\n",
      "Total # of fraudulent pts:  49200.0\n",
      "Out of (total) pts:  284807\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of Fradulent transactions:\n",
    "\n",
    "def percent_fraud(df):\n",
    "    return (len(df[df.Class==1])/len(df['Class']))*100\n",
    "\n",
    "# call the function to calculate the fraud percentage\n",
    "percentage = percent_fraud(df)\n",
    "\n",
    "print('Fraudulent percentage = ', percentage)\n",
    "print('Total # of fraudulent pts: ', percentage*df.shape[0])\n",
    "print('Out of (total) pts: ', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, randomly split the dataset into the training and testing sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = df.columns.values\n",
    "X = df[features[:-1]]\n",
    "y = df[features[-1]]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing data:  (56962, 56962)\n",
      "Number of training data:  (227845, 227845)\n"
     ]
    }
   ],
   "source": [
    "print('Number of testing data: ',(len(X_test),len(y_test)))\n",
    "print('Number of training data: ', (len(X_train),len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***For the purpose of this project, we pick a model that produces binary classification prediction. I am going to try 3 supervised classification algorithms namely Logistics Regression, Naives Bayes Theorem, and Random Forest (based on CART). We will then evaluate them and pick the best one.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Naive Bayes Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB()\n",
    "\n",
    "gnb.fit(X_train,y_train)\n",
    "gnb_predicted_y = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Naive Bayes: \n",
      " [[56486   373]\n",
      " [   39    64]]\n",
      "Accuracy Score:  0.9927671078964924\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Confusion Matrix for Naive Bayes: \\n', confusion_matrix(y_test,gnb_predicted_y))\n",
    "print('Accuracy Score: ',accuracy_score(y_test,gnb_predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tram ngo\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lgr=LogisticRegression()\n",
    "\n",
    "lgr.fit(X_train,y_train)\n",
    "lgr_predicted_y = lgr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99971598e-01 2.84019578e-05]\n",
      " [9.99991478e-01 8.52159469e-06]\n",
      " [9.99937532e-01 6.24684477e-05]\n",
      " [9.99989506e-01 1.04938823e-05]\n",
      " [9.99989950e-01 1.00498640e-05]\n",
      " [9.96623851e-01 3.37614902e-03]\n",
      " [9.99967368e-01 3.26317022e-05]\n",
      " [9.99980392e-01 1.96079770e-05]\n",
      " [9.99999992e-01 7.64771223e-09]\n",
      " [9.99980876e-01 1.91236378e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(lgr.predict_proba(X_test[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Logistic Regression: \n",
      " [[56846    13]\n",
      " [   41    62]]\n",
      "Accuracy Score:  0.9990519995786665\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix for Logistic Regression: \\n', confusion_matrix(y_test,lgr_predicted_y))\n",
    "print('Accuracy Score: ',accuracy_score(y_test,lgr_predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=0) \n",
    "                            # n_estimators is the number of trees in the forest, by default is equal to 100 \n",
    "clf.fit(X_train,y_train)\n",
    "clf_predicted_y = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Random Forest: \n",
      " [[56851     8]\n",
      " [   37    66]]\n",
      "Accuracy Score:  0.9992099996488887\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix for Random Forest: \\n', confusion_matrix(y_test,clf_predicted_y))\n",
    "print('Accuracy Score: ',accuracy_score(y_test,clf_predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning: Managing Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the strategy of Random Over-sampling, meaning that we will replicate the few class 0 instances and add them to the datasets to make them more representative within the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the classes\n",
    "df_fraud_class = y_train[y_train==1]\n",
    "df_nonfraud_class = y_train[y_train==0]\n",
    "\n",
    "# Count the instances:\n",
    "count_class_0 = len(df_nonfraud_class)\n",
    "count_class_1 = len(df_fraud_class)\n",
    "\n",
    "df_fraud_class = df_fraud_class.sample(count_class_1, replace=True)\n",
    "df_nonfraud_class = df_nonfraud_class.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_fraud_class, df_nonfraud_class], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the new training sets\n",
    "# Since Random Forest performs the best in the dataset below, we are only going to implement the algorithm here\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=0) \n",
    "                            # n_estimators is the number of trees in the forest, by default is equal to 100 \n",
    "clf.fit(X_train,df_test_over)\n",
    "clf_predicted_y = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Random Forest: \n",
      " [[56859     0]\n",
      " [  103     0]]\n",
      "Accuracy Score:  0.9981917769741231\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix for Random Forest: \\n', confusion_matrix(y_test,clf_predicted_y))\n",
    "print('Accuracy Score: ',accuracy_score(y_test,clf_predicted_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
